{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"gpuType":"T4","include_colab_link":true,"name":"Macrocircuits","provenance":[],"toc_visible":true},"kernel":{"display_name":"Python 3","language":"python","name":"python3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/projects/project-notebooks/Macrocircuits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/projects/project-notebooks/Macrocircuits.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>","metadata":{"execution":{}}},{"cell_type":"markdown","source":"# Macrocircuits\n\n***Macrocircuits: Leveraging neural architectural priors and modularity in embodied agents***\n\n**By Neuromatch Academy**\n\n**Content creators:** Divyansha Lachi, Kseniia Shilova  \n\n**Content reviewers:** Eva Dyer, Hannah Choi  \n\n__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk\n\n---","metadata":{"execution":{}}},{"cell_type":"markdown","source":"## Background\nThis project explores how we can build a biologically inspired artificial neural network (ANN) architecture, derived from the C. Elegans motor circuit, for the control of a simulated Swimmer agent. Traditional motor control ANNs often rely on generic, fully connected multilayer perceptrons (MLPs), which demand extensive training data, offer limited transferability, and possess complex internal dynamics that challenge interpretability. The project aims to understand how the biologically motivated ANN, which is shaped by evolution to be highly structured and sparse, could help to solve these problems and provide advantages in the domain of motor control. We will train MLPs using algorithms such as PPO, DDPG, and ES, and compare their performance in terms of rewards and sample efficiency with our bio-inspired ANN. The project also includes visualizing the C. Elegans connectome and building the network using this circuitry. We will conduct various ablation analyses by removing sign and weight-sharing constraints, and altering environmental parameters like the swimmerâ€™s length or viscosity. These investigations aim to understand how architecture and modularity impact performance and learning across different environments. Finally, the project aims at building an agent that is robust to environmental variations, navigating towards specific targets, and enhancing our understanding of bio-inspired motor control.  \n\n\n**Relevant references:**  \n\n- [Neural circuit architectural priors for embodied control](https://arxiv.org/abs/2201.05242)  \n- [Hierarchical motor control in mammals and machines](https://www.nature.com/articles/s41467-019-13239-6)  \n- [Continuous control with deep reinforcement learning](https://arxiv.org/pdf/1509.02971.pdf)  \n\n*This notebook uses code from the following GitHub repository:* [ncap](https://github.com/nikhilxb/ncap) by Nikhil X. Bhattasali and Anthony M. Zador and Tatiana A. Engel.\n\n**Infrastructure note:** This notebook contains GPU install guide as well as CPU ones for different OS.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"## Notebook Specific Instructions\n\nThis is made to experiment with different environmental settings here. Delete everything from the old notebook and then add things back piecemeal and modify as desired. Best to have both notebooks open on dual monitors if possible.","metadata":{}},{"cell_type":"markdown","source":"**Tutorial links**\n\nThis particular project connects a couple of distinct ideas explored throughout the course. Firstly, the innate ability to learn a certain set of actions quickly is the main topic of [Tutorial 4](https://neuroai.neuromatch.io/tutorials/W2D4_Macrolearning/student/W2D4_Tutorial4.html) for **W2D4** on biological meta-learning. The focus comes with the observation that the brain is not of a generic architecture but is a highly structured and optimized hierarchy of modules, the importance of which is highlighted in [Tutorial 3](https://neuroai.neuromatch.io/tutorials/W2D1_Macrocircuits/student/W2D1_Tutorial3.html) for **W2D1**, forming inductive bias for efficient motor control. The default model for the agent used here is already known Actor-Critic; you had the opportunity to observe in already mentioned tutorials as well as in [Tutorial 3](https://neuroai.neuromatch.io/tutorials/W1D2_ComparingTasks/student/W1D2_Tutorial3.html) for **W1D2**.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"---\n## Section 0: Initial setup","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Installing Dependencies (Kaggle GPU case, uncomment if you want to use this one)\n\nimport subprocess\n\nsubprocess.run([\"sudo\", \"apt-get\", \"install\", \"-y\", \"libgl1-mesa-glx\", \"libosmesa6\"])\nsubprocess.run([\"pip\", \"install\", \"-q\", \"imageio[ffmpeg]\"])\n\nprint('Installing dm_control...')\n!pip install -q dm_control>=1.0.16\n\n%env MUJOCO_GL=osmesa\n\n!echo Installed dm_control $(pip show dm_control | grep -Po \"(?<=Version: ).+\")\n!pip install -q dm-acme[envs]\n!mkdir output_videos","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-22T14:58:34.482275Z","iopub.execute_input":"2024-07-22T14:58:34.482588Z","iopub.status.idle":"2024-07-22T14:59:52.115258Z","shell.execute_reply.started":"2024-07-22T14:58:34.482563Z","shell.execute_reply":"2024-07-22T14:59:52.114080Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Reading package lists...\nBuilding dependency tree...\nReading state information...\nlibgl1-mesa-glx is already the newest version (21.2.6-0ubuntu0.1~20.04.2).\nThe following NEW packages will be installed:\n  libosmesa6\n0 upgraded, 1 newly installed, 0 to remove and 80 not upgraded.\nNeed to get 3054 kB of archives.\nAfter this operation, 13.8 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libosmesa6 amd64 21.2.6-0ubuntu0.1~20.04.2 [3054 kB]\n","output_type":"stream"},{"name":"stderr","text":"dpkg-preconfigure: unable to re-open stdin: No such file or directory\n","output_type":"stream"},{"name":"stdout","text":"Fetched 3054 kB in 1s (2628 kB/s)\nSelecting previously unselected package libosmesa6:amd64.\n(Reading database ... 113807 files and directories currently installed.)\nPreparing to unpack .../libosmesa6_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\nUnpacking libosmesa6:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nSetting up libosmesa6:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\nInstalling dm_control...\nenv: MUJOCO_GL=osmesa\nInstalled dm_control 1.0.20\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Imports and Utility Functions**","metadata":{"execution":{}}},{"cell_type":"code","source":"#@title Importing Libraries\nimport numpy as np\nimport collections\nimport argparse\nimport os\nimport yaml\nimport typing as T\nimport imageio\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport pandas as pd\nimport seaborn as sns\nfrom IPython.display import HTML\n\nimport dm_control as dm\nimport dm_control.suite.swimmer as swimmer\nfrom dm_control.rl import control\nfrom dm_control.utils import rewards\nfrom dm_control import suite\nfrom dm_control.suite.wrappers import pixels\nfrom dm_control.suite.utils import randomizers # Austin added\n\nfrom acme import wrappers\n\nfrom torch import nn","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-22T14:59:52.117356Z","iopub.execute_input":"2024-07-22T14:59:52.117663Z","iopub.status.idle":"2024-07-22T14:59:57.460746Z","shell.execute_reply.started":"2024-07-22T14:59:52.117636Z","shell.execute_reply":"2024-07-22T14:59:57.459979Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#@title Utility code for displaying videos\ndef write_video(\n  filepath: os.PathLike,\n  frames: T.Iterable[np.ndarray],\n  fps: int = 60,\n  macro_block_size: T.Optional[int] = None,\n  quality: int = 10,\n  verbose: bool = False,\n  **kwargs,\n):\n  \"\"\"\n  Saves a sequence of frames as a video file.\n\n  Parameters:\n  - filepath (os.PathLike): Path to save the video file.\n  - frames (Iterable[np.ndarray]): An iterable of frames, where each frame is a numpy array.\n  - fps (int, optional): Frames per second, defaults to 60.\n  - macro_block_size (Optional[int], optional): Macro block size for video encoding, can affect compression efficiency.\n  - quality (int, optional): Quality of the output video, higher values indicate better quality.\n  - verbose (bool, optional): If True, prints the file path where the video is saved.\n  - **kwargs: Additional keyword arguments passed to the imageio.get_writer function.\n\n  Returns:\n  None. The video is written to the specified filepath.\n  \"\"\"\n\n  with imageio.get_writer(filepath,\n                        fps=fps,\n                        macro_block_size=macro_block_size,\n                        quality=quality,\n                        **kwargs) as video:\n    if verbose: print('Saving video to:', filepath)\n    for frame in frames:\n      video.append_data(frame)\n\n\ndef display_video(\n  frames: T.Iterable[np.ndarray],\n  filename='output_videos/temp.mp4',\n  fps=60,\n  **kwargs,\n):\n  \"\"\"\n  Displays a video within a Jupyter Notebook from an iterable of frames.\n\n  Parameters:\n  - frames (Iterable[np.ndarray]): An iterable of frames, where each frame is a numpy array.\n  - filename (str, optional): Temporary filename to save the video before display, defaults to 'output_videos/temp.mp4'.\n  - fps (int, optional): Frames per second for the video display, defaults to 60.\n  - **kwargs: Additional keyword arguments passed to the write_video function.\n\n  Returns:\n  HTML object: An HTML video element that can be displayed in a Jupyter Notebook.\n  \"\"\"\n\n  # Write video to a temporary file.\n  filepath = os.path.abspath(filename)\n  write_video(filepath, frames, fps=fps, verbose=False, **kwargs)\n\n  height, width, _ = frames[0].shape\n  dpi = 70\n  orig_backend = matplotlib.get_backend()\n  matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n  fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n  matplotlib.use(orig_backend)  # Switch back to the original backend.\n  ax.set_axis_off()\n  ax.set_aspect('equal')\n  ax.set_position([0, 0, 1, 1])\n  im = ax.imshow(frames[0])\n  def update(frame):\n    im.set_data(frame)\n    return [im]\n  interval = 1000/fps\n  anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n                                  interval=interval, blit=True, repeat=False)\n  return HTML(anim.to_html5_video())","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-22T14:59:57.461935Z","iopub.execute_input":"2024-07-22T14:59:57.462419Z","iopub.status.idle":"2024-07-22T14:59:57.475194Z","shell.execute_reply.started":"2024-07-22T14:59:57.462391Z","shell.execute_reply":"2024-07-22T14:59:57.474159Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"\nIn this notebook we will explore the major components essential for this project.\n\n\n*   **Understanding the DeepMind Control Suite Swimmer Agent:** We will begin by exploring the swimmer agent provided by the DeepMind Control Suite. This section includes a detailed exploration of the agent's API, task customization capabilities, and how to adapt the environment to fit our experimental needs.\n*   **Training Models Using Various Reinforcement Learning Algorithms:** Next, we move on to learn how can we train models for the agents we created. We will be using Tonic_RL library to train our model. We will first train a standard MLP model using the Proximal Policy Optimization (PPO) algorithm.\n\n* **Training the NCAP model:** Finally we will define the NCAP model from [Neural Circuit Architectural Priors for Embodied Control](https://arxiv.org/abs/2201.05242) paper. We will train it using PPO and compare it against the MLP model we trained before.\n\n","metadata":{"execution":{}}},{"cell_type":"markdown","source":"I'm putting rendering code here as well. With some modification to pass a specific filename.","metadata":{}},{"cell_type":"code","source":"\"\"\" Renders the current environment state to an image \"\"\"\ndef render(env):\n    return env.physics.render(camera_id=0, width=640, height=480)\n\n\"\"\" Tests a DeepMind control suite environment by executing a series of random actions \"\"\"\ndef test_dm_control(env, filename):\n    env = wrappers.CanonicalSpecWrapper(env, clip=True)\n    env = wrappers.SinglePrecisionWrapper(env)\n\n    spec = env.action_spec()\n    timestep = env.reset()\n    frames = [render(env)]\n\n    for _ in range(180): # changed to 3 second renderings\n        action = np.random.uniform(low=spec.minimum, high=spec.maximum, size=spec.shape)\n        timestep = env.step(action)\n        frames.append(render(env))\n    return display_video(frames, filename)\n\n\n# NOTE - not sure which of the registered worms this will slot the model into. \n# Wouldn't that break it? Seems like the action spaces would be different due to different joints ...\n# Since I'm unfamiliar with this API, my best guess is that it will be the swimmer that was last instantiated with the below API call\n# env = suite.load(task, worm, task_kwargs)\n# Therefore, may need to ensure that the pretrained models are the right ones for whichever worm loaded before rendering.\n\"\"\" Renders a video of a saved model checkpoint with the current environment, saves to output \"\"\"\ndef play_model(path, checkpoint='last',environment='default',seed=None, header=None):\n\n    \"\"\"\n\n    Plays a model within an environment and renders the gameplay to a video.\n\n    Parameters:\n    - path (str): Path to the directory containing the model and checkpoints.\n    - checkpoint (str): Specifies which checkpoint to use ('last', 'first', or a specific ID). 'none' indicates no checkpoint.\n    - environment (str): The environment to use. 'default' uses the environment specified in the configuration file.\n    - seed (int): Optional seed for reproducibility.\n    - header (str): Optional Python code to execute before initializing the model, such as importing libraries.\n    \"\"\"\n\n    if checkpoint == 'none':\n        # Use no checkpoint, the agent is freshly created.\n        checkpoint_path = None\n        tonic.logger.log('Not loading any weights')\n    else:\n        checkpoint_path = os.path.join(path, 'checkpoints')\n        if not os.path.isdir(checkpoint_path):\n            tonic.logger.error(f'{checkpoint_path} is not a directory')\n            checkpoint_path = None\n\n        # List all the checkpoints.\n        checkpoint_ids = []\n        for file in os.listdir(checkpoint_path):\n            if file[:5] == 'step_':\n                checkpoint_id = file.split('.')[0]\n                checkpoint_ids.append(int(checkpoint_id[5:]))\n\n        if checkpoint_ids:\n            if checkpoint == 'last':\n                # Use the last checkpoint.\n                checkpoint_id = max(checkpoint_ids)\n                checkpoint_path = os.path.join(checkpoint_path, f'step_{checkpoint_id}')\n            elif checkpoint == 'first':\n                # Use the first checkpoint.\n                checkpoint_id = min(checkpoint_ids)\n                checkpoint_path = os.path.join(checkpoint_path, f'step_{checkpoint_id}')\n            else:\n                # Use the specified checkpoint.\n                checkpoint_id = int(checkpoint)\n                if checkpoint_id in checkpoint_ids:\n                    checkpoint_path = os.path.join(checkpoint_path, f'step_{checkpoint_id}')\n                else:\n                    tonic.logger.error(f'Checkpoint {checkpoint_id} not found in {checkpoint_path}')\n                    checkpoint_path = None\n        else:\n            tonic.logger.error(f'No checkpoint found in {checkpoint_path}')\n            checkpoint_path = None\n\n    # Load the experiment configuration.\n    arguments_path = os.path.join(path, 'config.yaml')\n    with open(arguments_path, 'r') as config_file:\n        config = yaml.load(config_file, Loader=yaml.FullLoader)\n    config = argparse.Namespace(**config)\n\n    # Run the header first, e.g. to load an ML framework.\n    try:\n        if config.header:\n            exec(config.header)\n        if header:\n            exec(header)\n    except:\n        pass\n\n    # Build the agent.\n    agent = eval(config.agent)\n\n    # Build the environment.\n    if environment == 'default':\n        environment  = tonic.environments.distribute(lambda: eval(config.environment))\n    else:\n        environment  = tonic.environments.distribute(lambda: eval(environment))\n    if seed is not None:\n        environment.seed(seed)\n\n    # Initialize the agent.\n    agent.initialize(\n    observation_space=environment.observation_space,\n    action_space=environment.action_space,\n    seed=seed,\n    )\n\n    # Load the weights of the agent form a checkpoint.\n    if checkpoint_path:\n        agent.load(checkpoint_path)\n\n    steps = 0\n    test_observations = environment.start()\n    frames = [environment.render('rgb_array',camera_id=0, width=640, height=480)[0]]\n    score, length = 0, 0\n\n    while True:\n        # Select an action.\n        actions = agent.test_step(test_observations, steps)\n        assert not np.isnan(actions.sum())\n\n        # Take a step in the environment.\n        test_observations, infos = environment.step(actions)\n        frames.append(environment.render('rgb_array',camera_id=0, width=640, height=480)[0])\n        agent.test_update(**infos, steps=steps)\n\n        score += infos['rewards'][0]\n        length += 1\n\n        if infos['resets'][0]:\n          break\n        \n    # video_path = os.path.join(path, 'video.mp4')\n    model_name = video_path.split('/')[-1]\n    video_path = f'output_videos/{model_name}.mp4'\n\n    print('Reward for the run: ', score)\n    return display_video(frames,video_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:01:17.232687Z","iopub.execute_input":"2024-07-22T15:01:17.233028Z","iopub.status.idle":"2024-07-22T15:01:17.254498Z","shell.execute_reply.started":"2024-07-22T15:01:17.233002Z","shell.execute_reply":"2024-07-22T15:01:17.253760Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"---\n## Section 1: Create a DM Swimmer with a target objective\n\nWe will add a ball to the environment. In order to prevent too much sparsity in the reward signal, we will give positive reward if the worm reaches a certain buffer around the target.\n\nThat being said, this may still be too little reward, especially if the distance needed to travel is far away. In the swimmer task, a reward signal is available at each time step. To get closer to that density, we can have a gradation of reward emanating outwards from the target.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"Some notes about the environment.\n\nActually the default objective is to reach the target, and the rewards given are already smoothed out, just as I thought was necessary above. See the reference here and pay careful attention to their get_reward() func: https://github.com/google-deepmind/dm_control/blob/main/dm_control/suite/swimmer.py\n\nI think that we don't need an additional wrapper class for this, but it may still be helpful if we want to modify the smoothness of the reward signal, etc. I will just have all functions overriden for now and then can change at my leisure.\n\nFor better understanding of MuJoCo, skimming this notebook is pretty helpful: https://colab.research.google.com/github/google-deepmind/mujoco/blob/main/python/tutorial.ipynb#scrollTo=Xqo7pyX-n72M","metadata":{}},{"cell_type":"code","source":"_SWIM_SPEED = 0.1 # We can change later on\n\nclass Swim(swimmer.Swimmer):\n    \"\"\"\n    This provides the task for us to use. Previously they had the reward configured on the swim speed. Here we want as distance to the target.\n    \n    We will need to grab that from the environment somehow.\n    \n    Since we're no longer using the speed as a function of reward, pry can take that out of the constructor here.\n    \"\"\"\n    \n    # def __init__(self, target_distance, desired_speed=_SWIM_SPEED, **kwargs):\n    def __init__(self, desired_speed=_SWIM_SPEED, **kwargs):\n        super().__init__(**kwargs)\n        # self.target_distance = target_distance\n        self._desired_speed = desired_speed\n        \n    def initialize_episode(self, physics):\n        \"\"\"\n        This will set the physics. When it says by episode - not sure why it would be changing physics by episode since a standard RL process\n        may take millions of episodes.\n        \n        Is this overloading the term? Perhaps so. Because if we initialize the target a certain distance away then it will reset every\n        episode ...\n        \"\"\"\n        \n        physics.named.model.mat_rgba['target', 'a'] = 1\n        physics.named.model.mat_rgba['target_default', 'a'] = 1\n        physics.named.model.mat_rgba['target_highlight', 'a'] = 1\n        \n        physics.named.model.geom_pos['target', 'x'] = 0.5\n        \n        physics.model.opt.viscosity = 1\n        \n        # what's the difference between geom_pos and model.light_pos ?\n        # answer - one contains the position of the agent, other the light source for rendering.\n        \n        \n        # beginning copy of their code to change at will\n        # Random joint angles:\n        randomizers.randomize_limited_and_rotational_joints(physics, self.random)\n        # Random target position.\n        close_target = self.random.rand() < .2  # Probability of a close target.\n        target_box = .3 if close_target else 2\n        xpos, ypos = self.random.uniform(-target_box, target_box, size=2)\n        physics.named.model.geom_pos['target', 'x'] = xpos\n        physics.named.model.geom_pos['target', 'y'] = ypos\n        physics.named.model.light_pos['target_light', 'x'] = xpos\n        physics.named.model.light_pos['target_light', 'y'] = ypos\n\n        super().initialize_episode(physics)\n\n    def get_observation(self, physics):\n        \"\"\"\n        Note that in the NeuroMatch provided example, the observation did not include distance to target.\n        This is because they were only doing a swim task - add back in for us since we want the target in here.\n        \"\"\"\n        \n        \"\"\"Returns an observation of joint angles, body velocities and target.\"\"\"\n        obs = collections.OrderedDict()\n        obs['joints'] = physics.joints()\n        obs['to_target'] = physics.nose_to_target()\n        obs['body_velocities'] = physics.body_velocities()\n        return obs\n    \n    def get_reward(self, physics):\n        \"\"\"\n        Note that this is the default logic for reaching target with a smooth reward.\n        \n        If we'd like, here is where we can change the task to be the swim task or to be anything else.\n        \"\"\"\n\n        \"\"\"Returns a smooth reward.\"\"\"\n        target_size = physics.named.model.geom_size['target', 0]\n        return rewards.tolerance(physics.nose_to_target_dist(),\n                                 bounds=(0, target_size),\n                                 margin=5*target_size,\n                                 sigmoid='long_tail')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:04:24.490482Z","iopub.execute_input":"2024-07-22T15:04:24.491211Z","iopub.status.idle":"2024-07-22T15:04:24.504525Z","shell.execute_reply.started":"2024-07-22T15:04:24.491177Z","shell.execute_reply":"2024-07-22T15:04:24.503522Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Defining and registering worms\n\nAfter defining the task, we want to create different worms (or, swimmers) that will interact with it. Register them to the environment with some wrapper / context manager / etc at the top.\n\nI am not familiar with this abstraction so am not sure why this is the case, but only run the below cell once to register them with the environment.","metadata":{}},{"cell_type":"code","source":"@swimmer.SUITE.add()\ndef default_worm(\n  n_links=6,\n  desired_speed=_SWIM_SPEED,\n  time_limit=swimmer._DEFAULT_TIME_LIMIT,\n  random=None,\n  environment_kwargs={},\n):\n  \"\"\"Returns the Swim task for a n-link swimmer.\"\"\"\n  model_string, assets = swimmer.get_model_and_assets(n_links)\n  physics = swimmer.Physics.from_xml_string(model_string, assets=assets)\n  task = Swim(desired_speed=desired_speed, random=random)\n  return control.Environment(\n    physics,\n    task,\n    time_limit=time_limit,\n    control_timestep=swimmer._CONTROL_TIMESTEP,\n    **environment_kwargs,\n  )\n\n@swimmer.SUITE.add()\ndef worm_12_links(\n  n_links=12,\n  desired_speed=_SWIM_SPEED,\n  time_limit=swimmer._DEFAULT_TIME_LIMIT,\n  random=None,\n  environment_kwargs={},\n):\n  \"\"\"Returns the Swim task for a n-link swimmer.\"\"\"\n  model_string, assets = swimmer.get_model_and_assets(n_links)\n  physics = swimmer.Physics.from_xml_string(model_string, assets=assets)\n  task = Swim(desired_speed=desired_speed, random=random)\n  return control.Environment(\n    physics,\n    task,\n    time_limit=time_limit,\n    control_timestep=swimmer._CONTROL_TIMESTEP,\n    **environment_kwargs,\n  )\n\n\n# Add your worms to this list for looping over and rendering them all at once\nworms = ['default_worm', 'worm_12_links']","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:04:25.430709Z","iopub.execute_input":"2024-07-22T15:04:25.431059Z","iopub.status.idle":"2024-07-22T15:04:25.492208Z","shell.execute_reply.started":"2024-07-22T15:04:25.431032Z","shell.execute_reply":"2024-07-22T15:04:25.490843Z"},"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129;43m@swimmer\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSUITE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mdefault_worm\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mn_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdesired_speed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_SWIM_SPEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswimmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_DEFAULT_TIME_LIMIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43menvironment_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250;43m  \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Returns the Swim task for a n-link swimmer.\"\"\"\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mswimmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_and_assets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_links\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dm_control/utils/containers.py:74\u001b[0m, in \u001b[0;36mTaggedTasks.add.<locals>.wrap\u001b[0;34m(factory_func)\u001b[0m\n\u001b[1;32m     72\u001b[0m name \u001b[38;5;241m=\u001b[39m factory_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_overriding_keys:\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NAME_ALREADY_EXISTS\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks[name] \u001b[38;5;241m=\u001b[39m factory_func\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags:\n","\u001b[0;31mValueError\u001b[0m: A function named 'default_worm' already exists in the container and `allow_overriding_keys` is False."],"ename":"ValueError","evalue":"A function named 'default_worm' already exists in the container and `allow_overriding_keys` is False.","output_type":"error"}]},{"cell_type":"markdown","source":"Here we render the worms to the output_videos directory. This is where all videos will be rendered, including from some pretrained model checkpoints, etc.","metadata":{}},{"cell_type":"code","source":"# note this uses the same swimmer task for all worms\nfor worm in worms:\n    env = suite.load('swimmer', worm, task_kwargs={'random': 1}) # with seed for controlling the RNG\n    test_dm_control(env, filename=f'output_videos/{worm}_untrained.mp4')","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:04:36.580492Z","iopub.execute_input":"2024-07-22T15:04:36.580864Z","iopub.status.idle":"2024-07-22T15:05:16.424913Z","shell.execute_reply.started":"2024-07-22T15:04:36.580833Z","shell.execute_reply":"2024-07-22T15:05:16.423745Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Load tonic_rl and train models / test them on the environment\n\nNote that tonic is extremely annoying to deal with on your own PC. Because it's not set up as a pip package, you need to download the module's entire git repo to whatever subdirectory you're working in, and I found that this caused many annoying import headaches for me. It seems to work fine on Kaggle though, probably because the notebook itself is in root and / or may have less pip packages to get this confused with - not sure.","metadata":{}},{"cell_type":"code","source":"import contextlib\nimport io\n\nwith contextlib.redirect_stdout(io.StringIO()): #to suppress output\n    \n    # cloning tonic from their repo, not the main one, means that the pretrained models are also included\n    # to use them requires a swimmer agent with the same architecture that they define.\n    !git clone https://github.com/neuromatch/tonic\n    %cd tonic\n    \nfrom tonic.torch import models, normalizers\nimport torch\nimport tonic.torch","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:05:52.580205Z","iopub.execute_input":"2024-07-22T15:05:52.581322Z","iopub.status.idle":"2024-07-22T15:05:55.382767Z","shell.execute_reply.started":"2024-07-22T15:05:52.581283Z","shell.execute_reply":"2024-07-22T15:05:55.381646Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"The below function is for training both default MLPs and the NCAP model.","metadata":{}},{"cell_type":"code","source":"def train(\n  header,\n  agent,\n  environment,\n  name = 'test',\n  trainer = 'tonic.Trainer()',\n  before_training = None,\n  after_training = None,\n  parallel = 1,\n  sequential = 1,\n  seed = 0\n):\n  \"\"\"\n  Some additional parameters:\n\n  - before_training: Python code to execute immediately before the training loop commences, suitable for setup actions needed after initialization but prior to training.\n  - after_training: Python code to run once the training loop concludes, ideal for teardown or analytical purposes.\n  - parallel: The count of environments to execute in parallel. Limited to 1 in a Colab notebook, but if additional resources are available, this number can be increased to expedite training.\n  - sequential: The number of sequential steps the environment runs before sending observations back to the agent. This setting is useful for temporal batching. It can be disregarded for this tutorial's purposes.\n  - seed: The experiment's random seed, guaranteeing the reproducibility of the training process.\n\n  \"\"\"\n  # Capture the arguments to save them, e.g. to play with the trained agent.\n  args = dict(locals())\n\n  # Run the header first, e.g. to load an ML framework.\n  if header:\n    exec(header)\n\n  # Build the train and test environments.\n  _environment = environment\n  environment = tonic.environments.distribute(lambda: eval(_environment), parallel, sequential)\n  test_environment = tonic.environments.distribute(lambda: eval(_environment))\n\n\n  # Build the agent.\n  agent = eval(agent)\n  agent.initialize(\n    observation_space=test_environment.observation_space,\n    action_space=test_environment.action_space, seed=seed)\n\n  # Choose a name for the experiment.\n  if hasattr(test_environment, 'name'):\n    environment_name = test_environment.name\n  else:\n    environment_name = test_environment.__class__.__name__\n  if not name:\n    if hasattr(agent, 'name'):\n      name = agent.name\n    else:\n      name = agent.__class__.__name__\n    if parallel != 1 or sequential != 1:\n      name += f'-{parallel}x{sequential}'\n\n  # Initialize the logger to save data to the path environment/name/seed.\n  path = os.path.join('data', 'local', 'experiments', 'tonic', environment_name, name)\n  tonic.logger.initialize(path, script_path=None, config=args)\n\n  # Build the trainer.\n  trainer = eval(trainer)\n  trainer.initialize(\n    agent=agent,\n    environment=environment,\n    test_environment=test_environment,\n  )\n  # Run some code before training.\n  if before_training:\n    exec(before_training)\n\n  # Train.\n  trainer.run()\n\n  # Run some code after training.\n  if after_training:\n    exec(after_training)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:05:57.945275Z","iopub.execute_input":"2024-07-22T15:05:57.945682Z","iopub.status.idle":"2024-07-22T15:05:57.959961Z","shell.execute_reply.started":"2024-07-22T15:05:57.945642Z","shell.execute_reply":"2024-07-22T15:05:57.958999Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Below are some model definitions. I think that since we are switching tasks from pure swimming to reaching some target, we will need to retrain all of these models. We may need to do this each time the task is changed because that will change the rewards substantially of course.","metadata":{}},{"cell_type":"code","source":"def ppo_mlp_model(\n  actor_sizes=(64, 64),\n  actor_activation=torch.nn.Tanh,\n  critic_sizes=(64, 64),\n  critic_activation=torch.nn.Tanh,\n):\n\n  \"\"\"\n  Constructs an ActorCritic model with specified architectures for the actor and critic networks.\n\n  Parameters:\n  - actor_sizes (tuple): Sizes of the layers in the actor MLP.\n  - actor_activation (torch activation): Activation function used in the actor MLP.\n  - critic_sizes (tuple): Sizes of the layers in the critic MLP.\n  - critic_activation (torch activation): Activation function used in the critic MLP.\n\n  Returns:\n  - models.ActorCritic: An ActorCritic model comprising an actor and a critic with MLP torsos,\n    equipped with a Gaussian policy head for the actor and a value head for the critic,\n    along with observation normalization.\n  \"\"\"\n\n  return models.ActorCritic(\n    actor=models.Actor(\n      encoder=models.ObservationEncoder(),\n      torso=models.MLP(actor_sizes, actor_activation),\n      head=models.DetachedScaleGaussianPolicyHead(),\n    ),\n    critic=models.Critic(\n      encoder=models.ObservationEncoder(),\n      torso=models.MLP(critic_sizes, critic_activation),\n      head=models.ValueHead(),\n    ),\n    observation_normalizer=normalizers.MeanStd(),\n  )\n\n\n# environments call should be as follows\n# tonic.environments.ControlSuite(\"{TASK}-{SWIMMER AGENT NAME}\")\n# uncomment for a training run - trial this now\ntrain('import tonic.torch',\n      'tonic.torch.agents.PPO(model=ppo_mlp_model(actor_sizes=(256, 256), critic_sizes=(256,256)))',\n      'tonic.environments.ControlSuite(\"swimmer-default_worm\")',\n      name = 'mlp_256',\n      trainer = 'tonic.Trainer(steps=int(5e5),save_steps=int(1e5))')","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:58.893915Z","iopub.execute_input":"2024-07-22T15:07:58.894744Z","iopub.status.idle":"2024-07-22T15:24:12.653399Z","shell.execute_reply.started":"2024-07-22T15:07:58.894709Z","shell.execute_reply":"2024-07-22T15:24:12.652436Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m\u001b[32mConfig file saved to data/local/experiments/tonic/swimmer-default_worm/mlp_256/config.yaml\u001b[0m\n          Time left:  epoch 0:00:00  total 0:12:22          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.104\n  entropy                                               1.05\n  iterations                                              24\n  kl                                                 0.00884\n  loss                                              -0.00822\n  std                                                  0.692\n  stop                                                0.0312\ncritic                                                      \n  iterations                                              80\n  loss                                                  7.61\n  v                                                     5.36\ntest                                                        \n  action                                                    \n    max                                                 2.96\n    mean                                              0.0155\n    min                                                -2.54\n    size                                               5,000\n    std                                                0.704\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  339\n    mean                                                77.8\n    min                                                 6.07\n    size                                                   5\n    std                                                  131\ntrain                                                       \n  action                                                    \n    max                                                 2.81\n    mean                                            -0.00513\n    min                                                -3.19\n    size                                              20,000\n    std                                                0.698\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  990\n    mean                                                 226\n    min                                                 4.91\n    size                                                  20\n    std                                                  321\n  episodes                                                20\n  epoch seconds                                         36.2\n  epoch steps                                          2e+04\n  epochs                                                   1\n  seconds                                               36.2\n  steps                                                2e+04\n  steps per second                                       553\n  worker steps                                         2e+04\n\n\u001b[1m\u001b[32mLogging data to data/local/experiments/tonic/swimmer-default_worm/mlp_256/log.csv\u001b[0m\n          Time left:  epoch 0:00:00  total 0:13:15          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.107\n  entropy                                               1.04\n  iterations                                            35.4\n  kl                                                 0.00804\n  loss                                               -0.0108\n  std                                                  0.685\n  stop                                                0.0169\ncritic                                                      \n  iterations                                              80\n  loss                                                  23.1\n  v                                                     14.8\ntest                                                        \n  action                                                    \n    max                                                 2.55\n    mean                                              0.0106\n    min                                                -2.71\n    size                                               5,000\n    std                                                0.706\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  914\n    mean                                                 497\n    min                                                 6.23\n    size                                                   5\n    std                                                  392\ntrain                                                       \n  action                                                    \n    max                                                 3.23\n    mean                                              0.0173\n    min                                                -3.27\n    size                                              20,000\n    std                                                0.719\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  848\n    mean                                                 117\n    min                                                 5.29\n    size                                                  20\n    std                                                  244\n  episodes                                                40\n  epoch seconds                                           38\n  epoch steps                                          2e+04\n  epochs                                                   2\n  seconds                                               74.3\n  steps                                                4e+04\n  steps per second                                       526\n  worker steps                                         4e+04\n\n          Time left:  epoch 0:00:00  total 0:13:15          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                       0.0997\n  entropy                                               1.03\n  iterations                                            39.4\n  kl                                                 0.00934\n  loss                                              -0.00983\n  std                                                  0.678\n  stop                                                0.0152\ncritic                                                      \n  iterations                                              80\n  loss                                                   5.7\n  v                                                     24.8\ntest                                                        \n  action                                                    \n    max                                                 2.95\n    mean                                             -0.0274\n    min                                                -3.49\n    size                                               5,000\n    std                                                0.716\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  884\n    mean                                                 189\n    min                                                 5.75\n    size                                                   5\n    std                                                  348\ntrain                                                       \n  action                                                    \n    max                                                 3.09\n    mean                                             -0.0101\n    min                                                   -3\n    size                                              20,000\n    std                                                0.712\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  981\n    mean                                                 250\n    min                                                 4.08\n    size                                                  20\n    std                                                  356\n  episodes                                                60\n  epoch seconds                                         39.3\n  epoch steps                                          2e+04\n  epochs                                                   3\n  seconds                                                114\n  steps                                                6e+04\n  steps per second                                       509\n  worker steps                                         6e+04\n\n          Time left:  epoch 0:00:00  total 0:13:01          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.111\n  entropy                                                  1\n  iterations                                              66\n  kl                                                 0.00937\n  loss                                               -0.0119\n  std                                                  0.661\n  stop                                               0.00303\ncritic                                                      \n  iterations                                              80\n  loss                                                  3.28\n  v                                                     24.6\ntest                                                        \n  action                                                    \n    max                                                 2.66\n    mean                                             -0.0376\n    min                                                -2.95\n    size                                               5,000\n    std                                                 0.71\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  811\n    mean                                                 179\n    min                                                 8.81\n    size                                                   5\n    std                                                  316\ntrain                                                       \n  action                                                    \n    max                                                 3.11\n    mean                                             -0.0405\n    min                                                -3.45\n    size                                              20,000\n    std                                                0.713\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  953\n    mean                                                 165\n    min                                                 4.74\n    size                                                  20\n    std                                                  280\n  episodes                                                80\n  epoch seconds                                         40.4\n  epoch steps                                          2e+04\n  epochs                                                   4\n  seconds                                                154\n  steps                                                8e+04\n  steps per second                                       496\n  worker steps                                         8e+04\n\n          Time left:  epoch 0:00:00  total 0:12:37          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.116\n  entropy                                              0.974\n  iterations                                            54.8\n  kl                                                 0.00931\n  loss                                                -0.011\n  std                                                  0.641\n  stop                                                0.0073\ncritic                                                      \n  iterations                                              80\n  loss                                                  2.35\n  v                                                     22.1\ntest                                                        \n  action                                                    \n    max                                                 2.46\n    mean                                             -0.0606\n    min                                                -2.96\n    size                                               5,000\n    std                                                0.701\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  711\n    mean                                                 241\n    min                                                 9.01\n    size                                                   5\n    std                                                  293\ntrain                                                       \n  action                                                    \n    max                                                 3.06\n    mean                                             -0.0533\n    min                                                -3.21\n    size                                              20,000\n    std                                                0.707\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 213\n    min                                                  6.1\n    size                                                  20\n    std                                                  319\n  episodes                                               100\n  epoch seconds                                         40.7\n  epoch steps                                          2e+04\n  epochs                                                   5\n  seconds                                                195\n  steps                                                1e+05\n  steps per second                                       491\n  worker steps                                         1e+05\n\n\u001b[1m\u001b[32m\nSaving weights to data/local/experiments/tonic/swimmer-default_worm/mlp_256/checkpoints/step_100000.pt\u001b[0m\n          Time left:  epoch 0:00:00  total 0:12:11          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.104\n  entropy                                              0.956\n  iterations                                            68.6\n  kl                                                 0.00564\n  loss                                               -0.0105\n  std                                                  0.629\n  stop                                               0.00292\ncritic                                                      \n  iterations                                              80\n  loss                                                  3.74\n  v                                                     30.5\ntest                                                        \n  action                                                    \n    max                                                 2.87\n    mean                                             -0.0496\n    min                                                -2.82\n    size                                               5,000\n    std                                                0.725\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  917\n    mean                                                 190\n    min                                                 5.83\n    size                                                   5\n    std                                                  363\ntrain                                                       \n  action                                                    \n    max                                                  3.2\n    mean                                             -0.0412\n    min                                                -3.23\n    size                                              20,000\n    std                                                0.703\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 224\n    min                                                 6.45\n    size                                                  20\n    std                                                  307\n  episodes                                               120\n  epoch seconds                                         41.1\n  epoch steps                                          2e+04\n  epochs                                                   6\n  seconds                                                236\n  steps                                              1.2e+05\n  steps per second                                       486\n  worker steps                                       1.2e+05\n\n          Time left:  epoch 0:00:00  total 0:11:38          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.104\n  entropy                                              0.938\n  iterations                                            65.4\n  kl                                                  0.0104\n  loss                                               -0.0118\n  std                                                  0.619\n  stop                                               0.00306\ncritic                                                      \n  iterations                                              80\n  loss                                                  1.21\n  v                                                     17.2\ntest                                                        \n  action                                                    \n    max                                                 2.99\n    mean                                              0.0389\n    min                                                -2.96\n    size                                               5,000\n    std                                                0.704\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  776\n    mean                                                 308\n    min                                                 9.32\n    size                                                   5\n    std                                                  354\ntrain                                                       \n  action                                                    \n    max                                                 3.11\n    mean                                             -0.0137\n    min                                                -3.08\n    size                                              20,000\n    std                                                 0.71\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  775\n    mean                                                92.2\n    min                                                 4.78\n    size                                                  20\n    std                                                  182\n  episodes                                               140\n  epoch seconds                                         40.5\n  epoch steps                                          2e+04\n  epochs                                                   7\n  seconds                                                277\n  steps                                              1.4e+05\n  steps per second                                       494\n  worker steps                                       1.4e+05\n\n          Time left:  epoch 0:00:00  total 0:11:03          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.127\n  entropy                                              0.915\n  iterations                                            68.2\n  kl                                                 0.00858\n  loss                                               -0.0132\n  std                                                  0.604\n  stop                                               0.00293\ncritic                                                      \n  iterations                                              80\n  loss                                                  1.85\n  v                                                       22\ntest                                                        \n  action                                                    \n    max                                                 2.68\n    mean                                             -0.0769\n    min                                                -2.71\n    size                                               5,000\n    std                                                0.715\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  178\n    mean                                                44.3\n    min                                                 6.45\n    size                                                   5\n    std                                                 67.2\ntrain                                                       \n  action                                                    \n    max                                                  3.2\n    mean                                             -0.0493\n    min                                                -2.91\n    size                                              20,000\n    std                                                0.698\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 222\n    min                                                 3.98\n    size                                                  20\n    std                                                  311\n  episodes                                               160\n  epoch seconds                                         40.6\n  epoch steps                                          2e+04\n  epochs                                                   8\n  seconds                                                317\n  steps                                              1.6e+05\n  steps per second                                       493\n  worker steps                                       1.6e+05\n\n          Time left:  epoch 0:00:00  total 0:10:20          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                       0.0963\n  entropy                                              0.901\n  iterations                                            44.2\n  kl                                                 0.00899\n  loss                                              -0.00978\n  std                                                  0.596\n  stop                                                0.0113\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.842\n  v                                                     16.9\ntest                                                        \n  action                                                    \n    max                                                 2.75\n    mean                                              -0.166\n    min                                                -2.94\n    size                                               5,000\n    std                                                0.739\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                 53.6\n    mean                                                18.5\n    min                                                  5.8\n    size                                                   5\n    std                                                 17.7\ntrain                                                       \n  action                                                    \n    max                                                 3.53\n    mean                                              -0.033\n    min                                                -3.05\n    size                                              20,000\n    std                                                 0.71\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 169\n    min                                                 4.55\n    size                                                  20\n    std                                                  317\n  episodes                                               180\n  epoch seconds                                         36.8\n  epoch steps                                          2e+04\n  epochs                                                   9\n  seconds                                                354\n  steps                                              1.8e+05\n  steps per second                                       544\n  worker steps                                       1.8e+05\n\n          Time left:  epoch 0:00:00  total 0:09:42          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                       0.0964\n  entropy                                                0.9\n  iterations                                            59.6\n  kl                                                 0.00716\n  loss                                              -0.00939\n  std                                                  0.595\n  stop                                               0.00671\ncritic                                                      \n  iterations                                              80\n  loss                                                  2.39\n  v                                                     24.7\ntest                                                        \n  action                                                    \n    max                                                 3.12\n    mean                                              -0.075\n    min                                                -2.81\n    size                                               5,000\n    std                                                0.742\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  517\n    mean                                                 111\n    min                                                 5.41\n    size                                                   5\n    std                                                  203\ntrain                                                       \n  action                                                    \n    max                                                 3.18\n    mean                                              -0.117\n    min                                                -3.45\n    size                                              20,000\n    std                                                0.722\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 257\n    min                                                 5.28\n    size                                                  20\n    std                                                  371\n  episodes                                               200\n  epoch seconds                                         39.3\n  epoch steps                                          2e+04\n  epochs                                                  10\n  seconds                                                394\n  steps                                                2e+05\n  steps per second                                       509\n  worker steps                                         2e+05\n\n\u001b[1m\u001b[32m\nSaving weights to data/local/experiments/tonic/swimmer-default_worm/mlp_256/checkpoints/step_200000.pt\u001b[0m\n          Time left:  epoch 0:00:00  total 0:09:03          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                       0.0934\n  entropy                                              0.876\n  iterations                                            37.8\n  kl                                                 0.00759\n  loss                                              -0.00998\n  std                                                  0.581\n  stop                                                0.0159\ncritic                                                      \n  iterations                                              80\n  loss                                                  0.96\n  v                                                     21.7\ntest                                                        \n  action                                                    \n    max                                                 2.99\n    mean                                             -0.0463\n    min                                                -3.34\n    size                                               5,000\n    std                                                0.754\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  672\n    mean                                                 153\n    min                                                   16\n    size                                                   5\n    std                                                  259\ntrain                                                       \n  action                                                    \n    max                                                 3.03\n    mean                                             -0.0319\n    min                                                -3.26\n    size                                              20,000\n    std                                                0.738\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 132\n    min                                                 6.76\n    size                                                  20\n    std                                                  305\n  episodes                                               220\n  epoch seconds                                         37.9\n  epoch steps                                          2e+04\n  epochs                                                  11\n  seconds                                                432\n  steps                                              2.2e+05\n  steps per second                                       528\n  worker steps                                       2.2e+05\n\n          Time left:  epoch 0:00:00  total 0:08:25          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.104\n  entropy                                              0.875\n  iterations                                              65\n  kl                                                 0.00701\n  loss                                               -0.0122\n  std                                                  0.581\n  stop                                               0.00308\ncritic                                                      \n  iterations                                              80\n  loss                                                  1.08\n  v                                                     26.5\ntest                                                        \n  action                                                    \n    max                                                 2.64\n    mean                                             -0.0748\n    min                                                -3.15\n    size                                               5,000\n    std                                                0.728\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  521\n    mean                                                 170\n    min                                                 6.67\n    size                                                   5\n    std                                                  205\ntrain                                                       \n  action                                                    \n    max                                                 2.82\n    mean                                             -0.0801\n    min                                                 -3.4\n    size                                              20,000\n    std                                                0.724\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  988\n    mean                                                 257\n    min                                                 6.34\n    size                                                  20\n    std                                                  348\n  episodes                                               240\n  epoch seconds                                         40.2\n  epoch steps                                          2e+04\n  epochs                                                  12\n  seconds                                                472\n  steps                                              2.4e+05\n  steps per second                                       497\n  worker steps                                       2.4e+05\n\n          Time left:  epoch 0:00:00  total 0:07:48          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                       0.0956\n  entropy                                              0.857\n  iterations                                            62.8\n  kl                                                 0.00842\n  loss                                               -0.0114\n  std                                                  0.571\n  stop                                               0.00637\ncritic                                                      \n  iterations                                              80\n  loss                                                  1.04\n  v                                                     24.7\ntest                                                        \n  action                                                    \n    max                                                 2.62\n    mean                                             -0.0403\n    min                                                -2.93\n    size                                               5,000\n    std                                                0.704\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  888\n    mean                                                 326\n    min                                                 6.73\n    size                                                   5\n    std                                                  376\ntrain                                                       \n  action                                                    \n    max                                                 2.98\n    mean                                             -0.0537\n    min                                                -3.17\n    size                                              20,000\n    std                                                0.718\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  900\n    mean                                                 213\n    min                                                 4.93\n    size                                                  20\n    std                                                  322\n  episodes                                               260\n  epoch seconds                                         40.6\n  epoch steps                                          2e+04\n  epochs                                                  13\n  seconds                                                513\n  steps                                              2.6e+05\n  steps per second                                       493\n  worker steps                                       2.6e+05\n\n          Time left:  epoch 0:00:00  total 0:07:08          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.103\n  entropy                                              0.838\n  iterations                                            37.6\n  kl                                                 0.00617\n  loss                                               -0.0109\n  std                                                   0.56\n  stop                                                 0.016\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.543\n  v                                                     15.8\ntest                                                        \n  action                                                    \n    max                                                 2.85\n    mean                                             -0.0759\n    min                                                -3.01\n    size                                               5,000\n    std                                                0.725\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  731\n    mean                                                 256\n    min                                                 5.36\n    size                                                   5\n    std                                                  303\ntrain                                                       \n  action                                                    \n    max                                                 3.06\n    mean                                             -0.0585\n    min                                                -3.15\n    size                                              20,000\n    std                                                0.728\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  684\n    mean                                                88.4\n    min                                                 4.63\n    size                                                  20\n    std                                                  184\n  episodes                                               280\n  epoch seconds                                           38\n  epoch steps                                          2e+04\n  epochs                                                  14\n  seconds                                                551\n  steps                                              2.8e+05\n  steps per second                                       526\n  worker steps                                       2.8e+05\n\n          Time left:  epoch 0:00:00  total 0:06:28          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.106\n  entropy                                              0.841\n  iterations                                            34.8\n  kl                                                  0.0108\n  loss                                               -0.0126\n  std                                                  0.562\n  stop                                                0.0172\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.552\n  v                                                     14.9\ntest                                                        \n  action                                                    \n    max                                                 2.85\n    mean                                             -0.0717\n    min                                                -2.98\n    size                                               5,000\n    std                                                0.701\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  224\n    mean                                                54.5\n    min                                                 7.12\n    size                                                   5\n    std                                                 84.7\ntrain                                                       \n  action                                                    \n    max                                                 3.07\n    mean                                               -0.13\n    min                                                -3.11\n    size                                              20,000\n    std                                                0.722\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 187\n    min                                                 4.98\n    size                                                  20\n    std                                                  309\n  episodes                                               300\n  epoch seconds                                         37.6\n  epoch steps                                          2e+04\n  epochs                                                  15\n  seconds                                                588\n  steps                                                3e+05\n  steps per second                                       532\n  worker steps                                         3e+05\n\n\u001b[1m\u001b[32m\nSaving weights to data/local/experiments/tonic/swimmer-default_worm/mlp_256/checkpoints/step_300000.pt\u001b[0m\n          Time left:  epoch 0:00:00  total 0:05:49          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.109\n  entropy                                              0.826\n  iterations                                              36\n  kl                                                 0.00808\n  loss                                                -0.012\n  std                                                  0.554\n  stop                                                0.0167\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.394\n  v                                                     14.2\ntest                                                        \n  action                                                    \n    max                                                 2.61\n    mean                                             -0.0448\n    min                                                -2.78\n    size                                               5,000\n    std                                                0.705\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  799\n    mean                                                 404\n    min                                                 6.06\n    size                                                   5\n    std                                                  340\ntrain                                                       \n  action                                                    \n    max                                                 2.99\n    mean                                              -0.137\n    min                                                -3.07\n    size                                              20,000\n    std                                                0.722\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  421\n    mean                                                69.3\n    min                                                 4.66\n    size                                                  20\n    std                                                  130\n  episodes                                               320\n  epoch seconds                                         37.6\n  epoch steps                                          2e+04\n  epochs                                                  16\n  seconds                                                626\n  steps                                              3.2e+05\n  steps per second                                       532\n  worker steps                                       3.2e+05\n\n          Time left:  epoch 0:00:00  total 0:05:11          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.117\n  entropy                                              0.802\n  iterations                                            65.8\n  kl                                                 0.00977\n  loss                                               -0.0136\n  std                                                  0.541\n  stop                                               0.00304\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.406\n  v                                                     17.5\ntest                                                        \n  action                                                    \n    max                                                 2.64\n    mean                                             -0.0958\n    min                                                   -3\n    size                                               5,000\n    std                                                0.737\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  526\n    mean                                                 134\n    min                                                 7.81\n    size                                                   5\n    std                                                  197\ntrain                                                       \n  action                                                    \n    max                                                 2.69\n    mean                                             -0.0591\n    min                                                -2.86\n    size                                              20,000\n    std                                                0.715\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  946\n    mean                                                 163\n    min                                                  4.9\n    size                                                  20\n    std                                                  266\n  episodes                                               340\n  epoch seconds                                         40.3\n  epoch steps                                          2e+04\n  epochs                                                  17\n  seconds                                                667\n  steps                                              3.4e+05\n  steps per second                                       497\n  worker steps                                       3.4e+05\n\n          Time left:  epoch 0:00:00  total 0:04:31          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.129\n  entropy                                               0.79\n  iterations                                            33.2\n  kl                                                 0.00879\n  loss                                               -0.0131\n  std                                                  0.534\n  stop                                                0.0226\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.398\n  v                                                     10.5\ntest                                                        \n  action                                                    \n    max                                                 3.13\n    mean                                             -0.0689\n    min                                                -2.68\n    size                                               5,000\n    std                                                0.716\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  558\n    mean                                                 125\n    min                                                 5.24\n    size                                                   5\n    std                                                  217\ntrain                                                       \n  action                                                    \n    max                                                 2.62\n    mean                                              -0.155\n    min                                                -3.14\n    size                                              20,000\n    std                                                0.729\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  666\n    mean                                                81.3\n    min                                                 4.24\n    size                                                  20\n    std                                                  152\n  episodes                                               360\n  epoch seconds                                         35.7\n  epoch steps                                          2e+04\n  epochs                                                  18\n  seconds                                                702\n  steps                                              3.6e+05\n  steps per second                                       560\n  worker steps                                       3.6e+05\n\n          Time left:  epoch 0:00:00  total 0:03:52          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.116\n  entropy                                              0.791\n  iterations                                            37.6\n  kl                                                  0.0111\n  loss                                               -0.0122\n  std                                                  0.534\n  stop                                                0.0213\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.625\n  v                                                     10.5\ntest                                                        \n  action                                                    \n    max                                                 2.81\n    mean                                              -0.136\n    min                                                -2.75\n    size                                               5,000\n    std                                                0.739\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  430\n    mean                                                 100\n    min                                                 9.31\n    size                                                   5\n    std                                                  165\ntrain                                                       \n  action                                                    \n    max                                                 2.95\n    mean                                              -0.125\n    min                                                -3.42\n    size                                              20,000\n    std                                                0.757\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  941\n    mean                                                 103\n    min                                                 5.44\n    size                                                  20\n    std                                                  232\n  episodes                                               380\n  epoch seconds                                         37.8\n  epoch steps                                          2e+04\n  epochs                                                  19\n  seconds                                                740\n  steps                                              3.8e+05\n  steps per second                                       530\n  worker steps                                       3.8e+05\n\n          Time left:  epoch 0:00:00  total 0:03:13          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.123\n  entropy                                              0.798\n  iterations                                            67.4\n  kl                                                  0.0101\n  loss                                               -0.0166\n  std                                                  0.539\n  stop                                               0.00593\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.277\n  v                                                     5.95\ntest                                                        \n  action                                                    \n    max                                                 2.71\n    mean                                              -0.222\n    min                                                -3.06\n    size                                               5,000\n    std                                                0.735\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  922\n    mean                                                 264\n    min                                                 6.62\n    size                                                   5\n    std                                                  359\ntrain                                                       \n  action                                                    \n    max                                                 2.86\n    mean                                              -0.173\n    min                                                -3.42\n    size                                              20,000\n    std                                                0.737\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  446\n    mean                                                78.5\n    min                                                 5.69\n    size                                                  20\n    std                                                  141\n  episodes                                               400\n  epoch seconds                                         39.6\n  epoch steps                                          2e+04\n  epochs                                                  20\n  seconds                                                780\n  steps                                                4e+05\n  steps per second                                       505\n  worker steps                                         4e+05\n\n\u001b[1m\u001b[32m\nSaving weights to data/local/experiments/tonic/swimmer-default_worm/mlp_256/checkpoints/step_400000.pt\u001b[0m\n          Time left:  epoch 0:00:00  total 0:02:34          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                       0.0925\n  entropy                                              0.795\n  iterations                                            11.2\n  kl                                                 0.00996\n  loss                                              -0.00951\n  std                                                  0.537\n  stop                                                0.0893\ncritic                                                      \n  iterations                                              80\n  loss                                                  1.59\n  v                                                     23.5\ntest                                                        \n  action                                                    \n    max                                                 2.96\n    mean                                              -0.232\n    min                                                -3.06\n    size                                               5,000\n    std                                                0.742\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  509\n    mean                                                 192\n    min                                                 6.21\n    size                                                   5\n    std                                                  214\ntrain                                                       \n  action                                                    \n    max                                                 2.91\n    mean                                              -0.122\n    min                                                -2.98\n    size                                              20,000\n    std                                                0.751\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 271\n    min                                                    5\n    size                                                  20\n    std                                                  353\n  episodes                                               420\n  epoch seconds                                         35.8\n  epoch steps                                          2e+04\n  epochs                                                  21\n  seconds                                                816\n  steps                                              4.2e+05\n  steps per second                                       558\n  worker steps                                       4.2e+05\n\n          Time left:  epoch 0:00:00  total 0:01:56          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.108\n  entropy                                              0.787\n  iterations                                            68.6\n  kl                                                  0.0059\n  loss                                               -0.0154\n  std                                                  0.533\n  stop                                               0.00292\ncritic                                                      \n  iterations                                              80\n  loss                                                  1.54\n  v                                                       18\ntest                                                        \n  action                                                    \n    max                                                 2.64\n    mean                                                -0.2\n    min                                                -3.01\n    size                                               5,000\n    std                                                0.752\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                   35\n    mean                                                17.3\n    min                                                 5.89\n    size                                                   5\n    std                                                 9.93\ntrain                                                       \n  action                                                    \n    max                                                 3.23\n    mean                                               -0.17\n    min                                                -3.13\n    size                                              20,000\n    std                                                0.765\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  890\n    mean                                                 224\n    min                                                  4.9\n    size                                                  20\n    std                                                  332\n  episodes                                               440\n  epoch seconds                                         40.2\n  epoch steps                                          2e+04\n  epochs                                                  22\n  seconds                                                856\n  steps                                              4.4e+05\n  steps per second                                       498\n  worker steps                                       4.4e+05\n\n          Time left:  epoch 0:00:00  total 0:01:17          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.124\n  entropy                                              0.767\n  iterations                                            45.4\n  kl                                                 0.00772\n  loss                                               -0.0158\n  std                                                  0.523\n  stop                                                0.0132\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.932\n  v                                                     12.3\ntest                                                        \n  action                                                    \n    max                                                 2.54\n    mean                                              -0.164\n    min                                                -2.97\n    size                                               5,000\n    std                                                0.771\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                1e+03\n    mean                                                 211\n    min                                                 5.87\n    size                                                   5\n    std                                                  395\ntrain                                                       \n  action                                                    \n    max                                                 2.83\n    mean                                              -0.149\n    min                                                -3.32\n    size                                              20,000\n    std                                                0.765\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  859\n    mean                                                74.8\n    min                                                 4.54\n    size                                                  20\n    std                                                  189\n  episodes                                               460\n  epoch seconds                                         38.4\n  epoch steps                                          2e+04\n  epochs                                                  23\n  seconds                                                895\n  steps                                              4.6e+05\n  steps per second                                       521\n  worker steps                                       4.6e+05\n\n          Time left:  epoch 0:00:00  total 0:00:38          \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                        0.128\n  entropy                                              0.758\n  iterations                                            53.6\n  kl                                                 0.00794\n  loss                                               -0.0172\n  std                                                  0.518\n  stop                                               0.00746\ncritic                                                      \n  iterations                                              80\n  loss                                                 0.483\n  v                                                     8.67\ntest                                                        \n  action                                                    \n    max                                                 2.81\n    mean                                              -0.276\n    min                                                -2.89\n    size                                               5,000\n    std                                                0.723\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  653\n    mean                                                 150\n    min                                                 4.39\n    size                                                   5\n    std                                                  253\ntrain                                                       \n  action                                                    \n    max                                                 2.87\n    mean                                              -0.153\n    min                                                -3.03\n    size                                              20,000\n    std                                                0.759\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  725\n    mean                                                68.2\n    min                                                 5.01\n    size                                                  20\n    std                                                  168\n  episodes                                               480\n  epoch seconds                                         39.7\n  epoch steps                                          2e+04\n  epochs                                                  24\n  seconds                                                934\n  steps                                              4.8e+05\n  steps per second                                       503\n  worker steps                                       4.8e+05\n\n             Time left:  epoch 0:00:00  total               \u001b[0m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\u001b[44m\u001b[97m\nactor                                                       \n  clip fraction                                       0.0999\n  entropy                                              0.762\n  iterations                                            30.4\n  kl                                                 0.00751\n  loss                                               -0.0133\n  std                                                  0.519\n  stop                                                0.0263\ncritic                                                      \n  iterations                                              80\n  loss                                                  1.35\n  v                                                     15.3\ntest                                                        \n  action                                                    \n    max                                                 2.61\n    mean                                             -0.0573\n    min                                                -3.09\n    size                                               5,000\n    std                                                0.715\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                   5\n    std                                                    0\n  episode score                                             \n    max                                                  862\n    mean                                                 374\n    min                                                 11.8\n    size                                                   5\n    std                                                  330\ntrain                                                       \n  action                                                    \n    max                                                 2.79\n    mean                                              -0.158\n    min                                                -3.08\n    size                                              20,000\n    std                                                0.771\n  episode length                                            \n    max                                                1,000\n    mean                                               1e+03\n    min                                                1,000\n    size                                                  20\n    std                                                    0\n  episode score                                             \n    max                                                  996\n    mean                                                 175\n    min                                                 4.67\n    size                                                  20\n    std                                                  326\n  episodes                                               500\n  epoch seconds                                         37.6\n  epoch steps                                          2e+04\n  epochs                                                  25\n  seconds                                                972\n  steps                                                5e+05\n  steps per second                                       531\n  worker steps                                         5e+05\n\n\u001b[1m\u001b[32m\nSaving weights to data/local/experiments/tonic/swimmer-default_worm/mlp_256/checkpoints/step_500000.pt\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above training finishes properly. Once I test things for real tomorrow or Wednesday leaving this running during the tutorial session and then download all trained models to the github from Zahra.","metadata":{}},{"cell_type":"markdown","source":"The above code works just fine for training a new MLP model with PPO on a new environment with the swimmer aiming for a ball, along with a higher viscosity. Now copy the NCAP implementation.\n\nThe NCAP implementation is where I'll really want to change some things. I think that I can add some MLP components to it that will really help with robustness while still keeping the parameter counts much lower than a full MLP. So this will be more of a neuro symbolic architecture in some ways.\n\nHow to do this - instantiate the original NCAP code and then have another version of it that I will add the MLP to. Then I need to train all three of the models (potentially with different optimization algorithms although I think PPO is more than sufficient for this) and then see how they compare on this new task, along with the varying viscosity.\n\nI think I can add in a residual stream abstraction similar to transformers. That will be a very interesting experiment.","metadata":{}},{"cell_type":"markdown","source":"# NCAP definition","metadata":{}},{"cell_type":"code","source":"# ==================================================================================================\n# Weight constraints.\n\n\ndef excitatory(w, upper=None):\n    return w.clamp(min=0, max=upper)\n\n\ndef inhibitory(w, lower=None):\n    return w.clamp(min=lower, max=0)\n\n\ndef unsigned(w, lower=None, upper=None):\n    return w if lower is None and upper is None else w.clamp(min=lower, max=upper)\n\n\n# ==================================================================================================\n# Activation constraints.\n\n\ndef graded(x):\n    return x.clamp(min=0, max=1)\n\n\n# ==================================================================================================\n# Weight initialization.\n\n\ndef excitatory_uniform(shape=(1,), lower=0., upper=1.):\n    assert lower >= 0\n    return nn.init.uniform_(nn.Parameter(torch.empty(shape)), a=lower, b=upper)\n\n\ndef inhibitory_uniform(shape=(1,), lower=-1., upper=0.):\n    assert upper <= 0\n    return nn.init.uniform_(nn.Parameter(torch.empty(shape)), a=lower, b=upper)\n\n\ndef unsigned_uniform(shape=(1,), lower=-1., upper=1.):\n    return nn.init.uniform_(nn.Parameter(torch.empty(shape)), a=lower, b=upper)\n\n\ndef excitatory_constant(shape=(1,), value=1.):\n    return nn.Parameter(torch.full(shape, value))\n\n\ndef inhibitory_constant(shape=(1,), value=-1.):\n    return nn.Parameter(torch.full(shape, value))\n\n\ndef unsigned_constant(shape=(1,), lower=-1., upper=1., p=0.5):\n    with torch.no_grad():\n        weight = torch.empty(shape).uniform_(0, 1)\n        mask = weight < p\n        weight[mask] = upper\n        weight[~mask] = lower\n        return nn.Parameter(weight)\n    \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CE_NCAP(nn.Module):\n    \"\"\"C.-elegans-inspired neural circuit architectural prior.\"\"\"\n\n    def __init__(\n            self,\n            n_joints: int,\n            n_turn_joints: int = 1,\n            oscillator_period: int = 60,\n            use_weight_sharing: bool = True,\n            use_weight_constraints: bool = True,\n            use_weight_constant_init: bool = True,\n            include_proprioception: bool = True,\n            include_head_oscillators: bool = True,\n            include_speed_control: bool = False,\n            include_turn_control: bool = False,\n    ):\n        super().__init__()\n        self.n_joints = n_joints\n        self.n_turn_joints = n_turn_joints\n        self.oscillator_period = oscillator_period\n        self.include_proprioception = include_proprioception\n        self.include_head_oscillators = include_head_oscillators\n        self.include_speed_control = include_speed_control\n        self.include_turn_control = include_turn_control\n\n        # Log activity\n        self.connections_log = []\n\n        # Timestep counter (for oscillations).\n        self.timestep = 0\n\n        # Weight sharing switch function.\n        self.ws = lambda nonshared, shared: shared if use_weight_sharing else nonshared\n\n        # Weight constraint and init functions.\n        if use_weight_constraints:\n            self.exc = excitatory\n            self.inh = inhibitory\n            if use_weight_constant_init:\n                exc_param = excitatory_constant\n                inh_param = inhibitory_constant\n            else:\n                exc_param = excitatory_uniform\n                inh_param = inhibitory_uniform\n        else:\n            self.exc = unsigned\n            self.inh = unsigned\n            if use_weight_constant_init:\n                exc_param = inh_param = unsigned_constant\n            else:\n                exc_param = inh_param = unsigned_uniform\n\n        # Learnable parameters.\n        self.params = nn.ParameterDict()\n        if use_weight_sharing:\n            if self.include_proprioception:\n                self.params['bneuron_prop'] = exc_param()\n            if self.include_speed_control:\n                self.params['bneuron_speed'] = inh_param()\n            if self.include_turn_control:\n                self.params['bneuron_turn'] = exc_param()\n            if self.include_head_oscillators:\n                self.params['bneuron_osc'] = exc_param()\n            self.params['muscle_ipsi'] = exc_param()\n            self.params['muscle_contra'] = inh_param()\n        else:\n            for i in range(self.n_joints):\n                if self.include_proprioception and i > 0:\n                    self.params[f'bneuron_d_prop_{i}'] = exc_param()\n                    self.params[f'bneuron_v_prop_{i}'] = exc_param()\n\n                if self.include_speed_control:\n                    self.params[f'bneuron_d_speed_{i}'] = inh_param()\n                    self.params[f'bneuron_v_speed_{i}'] = inh_param()\n\n                if self.include_turn_control and i < self.n_turn_joints:\n                    self.params[f'bneuron_d_turn_{i}'] = exc_param()\n                    self.params[f'bneuron_v_turn_{i}'] = exc_param()\n\n                if self.include_head_oscillators and i == 0:\n                    self.params[f'bneuron_d_osc_{i}'] = exc_param()\n                    self.params[f'bneuron_v_osc_{i}'] = exc_param()\n\n                self.params[f'muscle_d_d_{i}'] = exc_param()\n                self.params[f'muscle_d_v_{i}'] = inh_param()\n                self.params[f'muscle_v_v_{i}'] = exc_param()\n                self.params[f'muscle_v_d_{i}'] = inh_param()\n\n    def reset(self):\n        self.timestep = 0\n\n    def log_activity(self, activity_type, neuron):\n        \"\"\"Logs an active connection between neurons.\"\"\"\n        self.connections_log.append((self.timestep, activity_type, neuron))\n\n    def forward(\n            self,\n            joint_pos,\n            right_control=None,\n            left_control=None,\n            speed_control=None,\n            timesteps=None,\n            log_activity=True,\n            log_file='log.txt'\n    ):\n        \"\"\"Forward pass.\n\n    Args:\n      joint_pos (torch.Tensor): Joint positions in [-1, 1], shape (..., n_joints).\n      right_control (torch.Tensor): Right turn control in [0, 1], shape (..., 1).\n      left_control (torch.Tensor): Left turn control in [0, 1], shape (..., 1).\n      speed_control (torch.Tensor): Speed control in [0, 1], 0 stopped, 1 fastest, shape (..., 1).\n      timesteps (torch.Tensor): Timesteps in [0, max_env_steps], shape (..., 1).\n\n    Returns:\n      (torch.Tensor): Joint torques in [-1, 1], shape (..., n_joints).\n    \"\"\"\n\n        exc = self.exc\n        inh = self.inh\n        ws = self.ws\n\n        # Separate into dorsal and ventral sensor values in [0, 1], shape (..., n_joints).\n        joint_pos_d = joint_pos.clamp(min=0, max=1)\n        joint_pos_v = joint_pos.clamp(min=-1, max=0).neg()\n\n        # Convert speed signal from acceleration into brake.\n        if self.include_speed_control:\n            assert speed_control is not None\n            speed_control = 1 - speed_control.clamp(min=0, max=1)\n\n        joint_torques = []  # [shape (..., 1)]\n        for i in range(self.n_joints):\n            bneuron_d = bneuron_v = torch.zeros_like(joint_pos[..., 0, None])  # shape (..., 1)\n\n            # B-neurons recieve proprioceptive input from previous joint to propagate waves down the body.\n            if self.include_proprioception and i > 0:\n                bneuron_d = bneuron_d + joint_pos_d[\n                    ..., i - 1, None] * exc(self.params[ws(f'bneuron_d_prop_{i}', 'bneuron_prop')])\n                bneuron_v = bneuron_v + joint_pos_v[\n                    ..., i - 1, None] * exc(self.params[ws(f'bneuron_v_prop_{i}', 'bneuron_prop')])\n                self.log_activity('exc', f'bneuron_d_prop_{i}')\n                self.log_activity('exc', f'bneuron_v_prop_{i}')\n\n            # Speed control unit modulates all B-neurons.\n            if self.include_speed_control:\n                bneuron_d = bneuron_d + speed_control * inh(\n                    self.params[ws(f'bneuron_d_speed_{i}', 'bneuron_speed')]\n                )\n                bneuron_v = bneuron_v + speed_control * inh(\n                    self.params[ws(f'bneuron_v_speed_{i}', 'bneuron_speed')]\n                )\n                self.log_activity('inh', f'bneuron_d_speed_{i}')\n                self.log_activity('inh', f'bneuron_v_speed_{i}')\n\n            # Turn control units modulate head B-neurons.\n            if self.include_turn_control and i < self.n_turn_joints:\n                assert right_control is not None\n                assert left_control is not None\n                turn_control_d = right_control.clamp(min=0, max=1)  # shape (..., 1)\n                turn_control_v = left_control.clamp(min=0, max=1)\n                bneuron_d = bneuron_d + turn_control_d * exc(\n                    self.params[ws(f'bneuron_d_turn_{i}', 'bneuron_turn')]\n                )\n                bneuron_v = bneuron_v + turn_control_v * exc(\n                    self.params[ws(f'bneuron_v_turn_{i}', 'bneuron_turn')]\n                )\n                self.log_activity('exc', f'bneuron_d_turn_{i}')\n                self.log_activity('exc', f'bneuron_v_turn_{i}')\n\n            # Oscillator units modulate first B-neurons.\n            if self.include_head_oscillators and i == 0:\n                if timesteps is not None:\n                    phase = timesteps.round().remainder(self.oscillator_period)\n                    mask = phase < self.oscillator_period // 2\n                    oscillator_d = torch.zeros_like(timesteps)  # shape (..., 1)\n                    oscillator_v = torch.zeros_like(timesteps)  # shape (..., 1)\n                    oscillator_d[mask] = 1.\n                    oscillator_v[~mask] = 1.\n                else:\n                    phase = self.timestep % self.oscillator_period  # in [0, oscillator_period)\n                    if phase < self.oscillator_period // 2:\n                        oscillator_d, oscillator_v = 1.0, 0.0\n                    else:\n                        oscillator_d, oscillator_v = 0.0, 1.0\n                bneuron_d = bneuron_d + oscillator_d * exc(\n                    self.params[ws(f'bneuron_d_osc_{i}', 'bneuron_osc')]\n                )\n                bneuron_v = bneuron_v + oscillator_v * exc(\n                    self.params[ws(f'bneuron_v_osc_{i}', 'bneuron_osc')]\n                )\n\n                self.log_activity('exc', f'bneuron_d_osc_{i}')\n                self.log_activity('exc', f'bneuron_v_osc_{i}')\n\n            # B-neuron activation.\n            bneuron_d = graded(bneuron_d)\n            bneuron_v = graded(bneuron_v)\n\n            # Muscles receive excitatory ipsilateral and inhibitory contralateral input.\n            muscle_d = graded(\n                bneuron_d * exc(self.params[ws(f'muscle_d_d_{i}', 'muscle_ipsi')]) +\n                bneuron_v * inh(self.params[ws(f'muscle_d_v_{i}', 'muscle_contra')])\n            )\n            muscle_v = graded(\n                bneuron_v * exc(self.params[ws(f'muscle_v_v_{i}', 'muscle_ipsi')]) +\n                bneuron_d * inh(self.params[ws(f'muscle_v_d_{i}', 'muscle_contra')])\n            )\n\n            # Joint torque from antagonistic contraction of dorsal and ventral muscles.\n            joint_torque = muscle_d - muscle_v\n            joint_torques.append(joint_torque)\n\n        self.timestep += 1\n\n        out = torch.cat(joint_torques, -1)  # shape (..., n_joints)\n        return out","metadata":{},"execution_count":null,"outputs":[]}]}